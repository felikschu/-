## 2024.12.15
昨天学习了感知机算法以及部分的支持向量机算法。说实话学习过程中有一种深刻的感触：数学没白学。不仅没白学，而且还远远没学够。

例如最简单的感知机模型，就是解决一个线性可分数据集的二分类问题，而且分类结果也不一定是唯一的。这里面的学习算法就是随机梯度下降，是本学期运筹学课上的内容。此外，在上学期的数值分析中也学习过。
很多时候数学系的学生会抱怨说学了一大堆没用的知识，但是现在接触了大创和一些统计学习内容，才发现这些知识确实都是必要的，如果没有事先学过这些内容的话就会导致学习曲线异常陡峭，初学者就没法把握算法思想的脉络，
而是深陷在数学概念与数学推导中。

再比如说支持向量机，这里面对数学的要求就更高了。这里面使用了诸多凸优化工具，比如，在**线性支持向量机与硬间隔最大化**上，用到了拉格朗日对偶性，KTT条件等，这些都是运筹学课程上的内容。首先，它把一个原始最优化问题
表示为了广义拉格朗日函数的极小极大问题，然后再考虑这个极小极大问题的对偶问题，利用解对偶问题来替代原始问题。再比如，在**线性支持向量机与软间隔最大化**上，由于线性不可分，因此要引入一个松弛变量,并在
目标函数中增加一个关于这个松弛变量的项作为补偿。以及，在**非线性支持向量机与核函数**中，运用了非常多的数学基础知识，比如构造希尔伯特空间等。

之前的slam大创项目亦是如此，其中运用了李代数的知识来刻画物体在空间中的运动，以及运用了诸多运筹优化、数值分析的内容来处理数据。

下学期我将学习《实变函数与泛函分析》，其实有理由相信，这门课相当重要，而且可以说是后续诸多统计学、机器学习的基础。例如应用随机过程，这门课里面有非常多的定义与概念甚至题目，都是用测度论的语言来刻画的，如果没有学习过实变函数就会相当吃力。
